{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637b327b-4b4d-4ed9-9918-818e5825c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch import autocast, GradScaler\n",
    "\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ecf779-64e2-4c53-930c-4bc96109fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional packages\n",
    "# !pip install hiera-transformer\n",
    "# !pip install -U pytorch_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f5a3f-8720-4222-a63c-b3605b61c5e7",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8aa514-908e-4e00-af7a-06830084b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_size = [36, 64]\n",
    "batchsize=16\n",
    "\n",
    "screen_chunk_size = 30\n",
    "screen_sampling_rate = 30\n",
    "\n",
    "response_chunk_size = 8\n",
    "response_sampling_rate = 8\n",
    "\n",
    "behavior_as_channels = True\n",
    "replace_nans_with_means = True\n",
    "\n",
    "dim_head = 64\n",
    "num_heads = 2\n",
    "drop_path_rate = 0\n",
    "mlp_ratio=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a43689-cdb6-4443-a57d-0a227fb65d45",
   "metadata": {},
   "source": [
    "### get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f1c64c-31a4-4391-85ef-6f35d7085c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "        #  'dynamic29513-3-5-Video-full',\n",
    "        #  'dynamic29514-2-9-Video-full',\n",
    "        #  'dynamic29755-2-8-Video-full',\n",
    "        #  'dynamic29647-19-8-Video-full',\n",
    "         'dynamic29156-11-10-Video-full',\n",
    "        #  'dynamic29623-4-9-Video-full',\n",
    "        #  'dynamic29515-10-12-Video-full',\n",
    "        #  'dynamic29234-6-9-Video-full',\n",
    "        #  'dynamic29712-5-9-Video-full',\n",
    "        #  'dynamic29228-2-10-Video-full'\n",
    "        ]\n",
    "\n",
    "full_paths = [path.join(\"/home/gchakrabarty/video_foundation_model/data\", f) for f in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e38a4f-a213-46c0-b2de-035ab1fba6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experanto.dataloaders import get_multisession_dataloader\n",
    "from experanto.configs import DEFAULT_CONFIG as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e5b246-5be9-4542-9fa5-267f677c0272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gchakrabarty/miniconda3/envs/sam2/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cfg.dataset.global_chunk_size = None\n",
    "cfg.dataset.global_sampling_rate = None\n",
    "\n",
    "cfg.dataset.modality_config.screen.chunk_size = screen_chunk_size\n",
    "cfg.dataset.modality_config.screen.sampling_rate = screen_sampling_rate\n",
    "cfg.dataset.modality_config.eye_tracker.chunk_size = screen_chunk_size\n",
    "cfg.dataset.modality_config.eye_tracker.sampling_rate = screen_sampling_rate\n",
    "cfg.dataset.modality_config.treadmill.chunk_size = screen_chunk_size\n",
    "cfg.dataset.modality_config.treadmill.sampling_rate = screen_sampling_rate\n",
    "\n",
    "cfg.dataset.modality_config.responses.chunk_size = response_chunk_size\n",
    "cfg.dataset.modality_config.responses.sampling_rate = response_sampling_rate\n",
    "\n",
    "cfg.dataset.modality_config.screen.sample_stride = 1\n",
    "cfg.dataset.modality_config.screen.include_blanks=True\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"train\"}\n",
    "cfg.dataset.modality_config.screen.transforms.Resize.size = video_size\n",
    "\n",
    "cfg.dataloader.num_workers = 2\n",
    "cfg.dataloader.prefetch_factor = 2\n",
    "cfg.dataloader.batch_size = batchsize\n",
    "cfg.dataloader.pin_memory = False\n",
    "cfg.dataloader.shuffle = True\n",
    "\n",
    "train_dl = get_multisession_dataloader(full_paths, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14b18d-346d-48c4-b12e-e7b8e0f28820",
   "metadata": {},
   "source": [
    "### get Hiera backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc0b8f9-b374-479f-b166-801bf9d22851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gchakrabarty/miniconda3/envs/sam2/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 18, 32, 192])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install hiera-transformer\n",
    "from hiera import Hiera\n",
    "tiny_hiera = Hiera(input_size=(screen_chunk_size, video_size[0], video_size[1]),\n",
    "                     num_heads=1,\n",
    "                     embed_dim=96,\n",
    "                     stages=(2, 1,), # 3 transformer layers \n",
    "                     q_pool=1, \n",
    "                     in_chans=1,\n",
    "                     q_stride=(1, 1, 1,),\n",
    "                     mask_unit_size=(1, 8, 8),\n",
    "                     patch_kernel=(5, 5, 5),\n",
    "                     patch_stride=(3, 2, 2),\n",
    "                     patch_padding=(1, 2, 2),\n",
    "                     sep_pos_embed=True,\n",
    "                     drop_path_rate=drop_path_rate,\n",
    "                     mlp_ratio=4,)\n",
    "\n",
    "tiny_hiera = tiny_hiera.cuda().to(torch.float32);\n",
    "example_input = torch.ones(8,1,screen_chunk_size, 36,64).to(\"cuda\", torch.float32)\n",
    "out = tiny_hiera(example_input, return_intermediates=True);\n",
    "\n",
    "hiera_output = out[-1][-1]\n",
    "hiera_output.shape # (b, t, h, w, c): (8, 4, 9, 16, 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e892e-0e01-4fda-bec9-13179f415692",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbce1ed2-9c69-43e0-91c9-a35fc2e4b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MouseHiera(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone,\n",
    "                 dls,\n",
    "                 chunk_size,\n",
    "                 dim=192,\n",
    "                 dim_head=32,\n",
    "                 num_heads=4,\n",
    "                 mlp_ratio=4,):\n",
    "        super().__init__()\n",
    "        self.backbone=backbone\n",
    "        self.num_heads=num_heads\n",
    "        self.dim_head=dim_head\n",
    "        self.dim=dim\n",
    "        self.dim_q = dim_head*num_heads\n",
    "        self.wq = nn.Linear(self.dim_q, self.dim_q, bias=False)\n",
    "        self.wk = nn.Linear(dim, self.dim_q, bias=False)\n",
    "        self.wv = nn.Linear(dim, self.dim_q, bias=False)\n",
    "        self.wo = nn.Linear(self.dim_q, self.dim_q, bias=False)\n",
    "        \n",
    "        self.neuron_proj = nn.Linear(self.dim_q, chunk_size, bias=False)\n",
    "        \n",
    "        \n",
    "        self.kv_norm=torch.nn.RMSNorm(dim)\n",
    "        self.q_norm=torch.nn.RMSNorm(self.dim_q)\n",
    "        self.qkv_norm=torch.nn.RMSNorm(self.dim_q)\n",
    "        self.mlp = MLP(dim=self.dim_q, hidden_dim=int(self.dim_q * mlp_ratio))\n",
    "        self.readout = nn.ModuleDict()\n",
    "        self.activation = nn.Softplus(beta=0.1) # probably a much better activation than ELU+1\n",
    "        for k, v in dls.loaders.items():\n",
    "            n_neurons = next(iter(v))[\"responses\"].shape[-1]\n",
    "            self.readout[k] = IndexedLinearReadout(n_neurons, \n",
    "                                                   in_features=dim_head*num_heads,\n",
    "                                                   dim_head=dim_head, \n",
    "                                                   num_heads=num_heads, \n",
    "                                                  )\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x, key):\n",
    "        x = self.backbone(x, return_intermediates=True)[-1][-1]\n",
    "        b, t, h, w, d = x.shape\n",
    "        x = self.kv_norm(x)\n",
    "        x = x.view(b, -1, d) # (B, t*h*w, D)\n",
    "        k, v = self.wk(x), self.wv(x)\n",
    "        q = self.q_norm(self.readout[key].query) # (1, N, D)\n",
    "        q = q.repeat(b, 1, 1) # repeat query for number of batches\n",
    "        q_attn = self.wq(q)\n",
    "        q_attn = q_attn.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2)\n",
    "        k = k.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2) # (B, H, S, D)\n",
    "        v = v.view(b, -1, self.num_heads, self.dim_head).transpose(1, 2) # (B, H, S, D)\n",
    "        with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "            o = F.scaled_dot_product_attention(q_attn, k, v)\n",
    "        # (B, H, S, D) -> (B, N, D), with N = num_neurons\n",
    "        o = o.transpose(1,2).contiguous().view(b, -1, self.dim_q)\n",
    "        o = self.wo(o) + q\n",
    "        o = self.qkv_norm(o)  \n",
    "        o = self.mlp(o) + o\n",
    "        o = self.neuron_proj(o) # (B, N, D) -> (B, N, t)\n",
    "        o = o + self.readout[key].bias\n",
    "        o = self.activation(o)\n",
    "        return o\n",
    "     \n",
    "    def init_weights(self, std=.5, cutoff_factor: int = 3):\n",
    "        \"\"\"See `TorchTitan <https://github.com/pytorch/torchtitan/blob/40a10263c5b3468ffa53b3ac98d80c9267d68155/torchtitan/models/llama/model.py#L403>`__.\"\"\"\n",
    "        std = self.dim_q**-0.5\n",
    "        for lin in (self.wq, self.wk, self.wv, self.wo):\n",
    "            nn.init.trunc_normal_(\n",
    "                lin.weight,\n",
    "                mean=0.0,\n",
    "                std=std,\n",
    "                a=-cutoff_factor * std,\n",
    "                b=cutoff_factor * std,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67d0ee7-016f-4046-bfd9-ae084ac69cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "    def init_weights(self, std=.5, cutoff_factor: int = 3):\n",
    "        \"\"\"See `TorchTitan <https://github.com/pytorch/torchtitan/blob/40a10263c5b3468ffa53b3ac98d80c9267d68155/torchtitan/models/llama/model.py#L403>`__.\"\"\"\n",
    "        nn.init.trunc_normal_(\n",
    "            self.net[0].weight,\n",
    "            mean=0.0,\n",
    "            std=std,\n",
    "            a=-cutoff_factor * std,\n",
    "            b=cutoff_factor * std,\n",
    "        )\n",
    "        nn.init.trunc_normal_(\n",
    "            self.net[2].weight,\n",
    "            mean=0.0,\n",
    "            std=std,\n",
    "            a=-cutoff_factor * std,\n",
    "            b=cutoff_factor * std,\n",
    "        )\n",
    "        self.net[0].bias.data.zero_()\n",
    "        self.net[2].bias.data.zero_()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f07a6270-174c-42d7-8f19-2591ca4ddb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedLinearReadout(nn.Module):\n",
    "    \"\"\"\n",
    "    Readout module for MTM models with selectable weights based on \n",
    "    input IDs. Based on :class:`torch.nn.Linear`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        unique_ids: int,\n",
    "        in_features: int = 384,\n",
    "        dim_head=32,\n",
    "        num_heads=4,\n",
    "        bias: bool = True,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.float32,\n",
    "        init_std: float = 0.02,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        self.unique_ids = unique_ids\n",
    "        self.in_features = in_features\n",
    "        self.init_std = init_std\n",
    "        self.query = nn.Parameter(\n",
    "            torch.empty(1, unique_ids, dim_head*num_heads, **factory_kwargs)\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(\n",
    "                torch.empty(1, unique_ids, 1, **factory_kwargs)\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self, cutoff_factor: int = 3):\n",
    "        \"\"\"See `TorchTitan <https://github.com/pytorch/torchtitan/blob/40a10263c5b3468ffa53b3ac98d80c9267d68155/torchtitan/models/llama/model.py#L403>`__.\"\"\"\n",
    "        readout_std = self.in_features**-0.5\n",
    "        nn.init.trunc_normal_(\n",
    "            self.query,\n",
    "            mean=0.0,\n",
    "            std=readout_std,\n",
    "            a=-cutoff_factor * readout_std,\n",
    "            b=cutoff_factor * readout_std,\n",
    "        )\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddde36-dfd5-44b3-8961-b67d970422a5",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512db87e-b274-4208-9579-0c36d322d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_dim = hiera_output[-1][-1].shape[-1]\n",
    "model = MouseHiera(backbone=tiny_hiera, \n",
    "                        dls=train_dl, \n",
    "                        chunk_size=response_chunk_size,\n",
    "                        dim=backbone_dim, \n",
    "                        dim_head=dim_head,\n",
    "                        num_heads=num_heads,\n",
    "                       mlp_ratio=mlp_ratio)\n",
    "model = model.to(torch.float32).cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db1feb-d92b-426b-925e-5ae114465d83",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce03e89e-23d5-4cbe-b96e-8ecb2cee2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pytorch_warmup\n",
    "import pytorch_warmup as warmup\n",
    "\n",
    "n_epochs = 200\n",
    "lr = 2e-4\n",
    "gradient_clipping = 1.0\n",
    "criteria = nn.PoissonNLLLoss(log_input=False, reduction='mean')\n",
    "opt = AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt,\n",
    "                                                          T_max=1e6, \n",
    "                                                          eta_min=1e-5)\n",
    "warmup_scheduler = warmup.UntunedLinearWarmup(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91982d-a5f5-4a86-86c8-c04280570032",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa59f4a-4b2c-40ec-a83b-ece17dddaee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2187it [06:22,  5.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# the first 10 batches are slow because torch is compiling the model for each new input shape\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (key, batch) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dl)):\n\u001b[1;32m      4\u001b[0m         videos \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mfloat32, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m         responses \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mfloat32, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/video_foundation_model/experanto/experanto/utils.py:142\u001b[0m, in \u001b[0;36mLongCycler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m cycles \u001b[38;5;241m=\u001b[39m [cycle(loader) \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, loader, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    138\u001b[0m     cycle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[1;32m    139\u001b[0m     (cycle(cycles)),\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaders) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batches),\n\u001b[1;32m    141\u001b[0m ):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m k, \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/video_foundation_model/experanto/experanto/utils.py:102\u001b[0m, in \u001b[0;36mcycle\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m         iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n",
      "File \u001b[0;32m~/video_foundation_model/experanto/experanto/utils.py:75\u001b[0m, in \u001b[0;36mMultiEpochsDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mshuffle_valid_screen_times()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/sam2/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# the first 10 batches are slow because torch is compiling the model for each new input shape\n",
    "for _ in range(n_epochs):\n",
    "    for i, (key, batch) in tqdm(enumerate(train_dl)):\n",
    "        videos = batch[\"screen\"].to(\"cuda\", torch.float32, non_blocking=True).transpose(1,2)\n",
    "        responses = batch[\"responses\"].to(\"cuda\", torch.float32, non_blocking=True)\n",
    "        with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            out = model(videos, key);\n",
    "        loss = criteria(out.transpose(1,2), responses)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clipping, norm_type=2)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        with warmup_scheduler.dampening():\n",
    "            lr_scheduler.step()\n",
    "    print(f\"Loss:{loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5853c7-80ef-41b5-8e9a-0ffd8d6569fa",
   "metadata": {},
   "source": [
    "# Validation dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f562f0-b5c3-40e1-9d0c-830a4fd050d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset.modality_config.screen.sample_stride = screen_chunk_size\n",
    "cfg.dataset.modality_config.screen.include_blanks=False\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"oracle\"}\n",
    "\n",
    "# example session\n",
    "val_dl = get_multisession_dataloader(full_paths[0:1], cfg)\n",
    "\n",
    "_, b = next(iter(val_dl))\n",
    "n_neurons = b[\"responses\"].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbe200-fa89-47f9-84dc-d77800010e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step():\n",
    "    from torchmetrics.regression import PearsonCorrCoef\n",
    "    r = PearsonCorrCoef(num_outputs=n_neurons).cuda()\n",
    "    with torch.no_grad():\n",
    "        for i, (k, b) in tqdm(enumerate(val_dl)):\n",
    "            videos = b[\"screen\"].to(\"cuda\", torch.float32, non_blocking=True).permute(0,2,1,3,4)\n",
    "            responses = b[\"responses\"].to(\"cuda\", torch.float32, non_blocking=True)\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                out = model(videos, k);\n",
    "            r.update(out.transpose(1,2).reshape(-1, n_neurons), responses.reshape(-1, n_neurons))\n",
    "    return r.compute().cpu().numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38759439-b2c9-4185-ba17-f13f2a7b42aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:05,  6.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(-0.00025154973)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395973c3-cc65-433e-b2f1-e1861f8cc13c",
   "metadata": {},
   "source": [
    "# Final Test Set Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699a4ac-c646-4919-93c8-58738449b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset.modality_config.screen.sample_stride = screen_chunk_size\n",
    "cfg.dataset.modality_config.screen.include_blanks=False\n",
    "cfg.dataset.modality_config.screen.valid_condition = {\"tier\": \"final_test_1\"}\n",
    "\n",
    "# example session\n",
    "val_dl = get_multisession_dataloader(full_paths[0:1], cfg)\n",
    "\n",
    "_, b = next(iter(val_dl))\n",
    "n_neurons = b[\"responses\"].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02367f-4906-4d85-871f-a2435b463bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step():\n",
    "    from torchmetrics.regression import PearsonCorrCoef\n",
    "    r = PearsonCorrCoef(num_outputs=n_neurons).cuda()\n",
    "    with torch.no_grad():\n",
    "        for i, (k, b) in tqdm(enumerate(val_dl)):\n",
    "            videos = b[\"screen\"].to(\"cuda\", torch.float32, non_blocking=True).permute(0,2,1,3,4)\n",
    "            responses = b[\"responses\"].to(\"cuda\", torch.float32, non_blocking=True)\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                out = model(videos, k);\n",
    "            r.update(out.transpose(1,2).reshape(-1, n_neurons), responses.reshape(-1, n_neurons))\n",
    "    return r.compute().cpu().numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e412b1a-b796-43e5-bd63-fb354162cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:05,  6.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.00028639115)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfdf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
